{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Advanced Skills"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Downsizing data with a specific ratio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1) Introduction\n",
    "Have you thought that given data with 5 labels, you can also do a binary classification? For example, we have 5 jets: t, q, g, w, z. Now instead of 5 Tagger, we only want to do the T Tagger, which means all the other jets are clustered to not-T. In this case, if we directly use the data, it results in input imbalance: T is only 1/4 of not-T. Thus we need to downsize the data so that elements are relatively balanced.<br><br>\n",
    "Additionally, for testing, we usually use part of the data, so downsizing is very necessary.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2) Code\n",
    "Generally we use the conditional silicing in pandas to accomplish this task."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load data\n",
    "load_path = \"data/samples.h5\"\n",
    "df = pd.read_hdf(load_path, key=\"data\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the data who meets the condition\n",
    "tJets = df[df['j_t']==1]\n",
    "\n",
    "print(\"There are %d constituents of T jets.\" %(tJets.shape[0]))"
   ]
  },
  {
   "source": [
    "However, we cannot directly split this Series. Instead, we want to split the data by jets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['j_t','j_q','j_g','j_w','j_z']\n",
    "jet_dict = {}\n",
    "for label in labels:\n",
    "    jet_dict[label] = np.unique(df[df[label]==1]['j_index'])"
   ]
  },
  {
   "source": [
    "Now we have a dictionary in which keys are labels and values are correpsponding jet indices.<br>\n",
    "Now lets take 100 for each jet."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_size = np.repeat([100],5)\n",
    "df100 = pd.DataFrame()\n",
    "\n",
    "for label, indices in jet_dict.items():\n",
    "    chosen_jets = np.random.choice(indices,size=jet_size[labels.index(label)], replace=False)\n",
    "    temp_df = df[df['j_index'].isin(chosen_jets)]\n",
    "    df100 = pd.concat([df100,temp_df],axis=0)\n",
    "\n",
    "df100.info()"
   ]
  },
  {
   "source": [
    "Here we have a dataset with 100 jets for each category."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3) Excercise\n",
    "Try to create a dataset with 500 jets for total but with ratio t:q:g:z:w = 3:2:1:0:0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. N-Constituents of Jets\n",
    "The amount of constituents varies in jets, ranging from 20 to more than 200. When we classify, we always expect to keep each jet containning the same number of constituents. For example, if we set n_con = 40, ranking by the transverse momentum (default), the first 40 constituents will be kept. If constituents in a jet are less than 40, we will use zero-padding."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform (nConstituents, data):\n",
    "    kColumns = data.columns.shape[0]\n",
    "\n",
    "    # we expect the output shape (mJets, nConstituents, kColumns)\n",
    "    jet_list = list(set(data['j_index']))\n",
    "    data_expected = []\n",
    "\n",
    "    for jet in tqdm(jet_list):\n",
    "        # Zero padding for insufficient jets. \n",
    "        # So we create a empty array and add signals in.\n",
    "        jet_frame = np.zeros((nConstituents, kColumns))\n",
    "        jet_temp = data[data['j_index']==jet].values\n",
    "        if (jet_temp.shape[0]<nConstituents):\n",
    "            for i, constituent in enumerate(jet_temp):\n",
    "                jet_frame[i] = constituent\n",
    "        else:\n",
    "            jet_frame = jet_temp[:nConstituents] + jet_frame\n",
    "        data_expected.append(jet_frame)\n",
    "    # \"j_index\" is useless for machine learning part. Drop it!\n",
    "\n",
    "    return np.array(data_expected)[:,:,:-1]"
   ]
  },
  {
   "source": [
    "## 3. Jet Clustering & Rotating\n",
    "### 1) Dependencies\n",
    "You need Linux to run \"pyjet\". This is the tutorial to install WSL: [WSL Tutorial](https://github.com/451488975/Anaconda_Setup/blob/master/CPU_with_WSL.ipynb)\n",
    "\n",
    "Make sure you have:\n",
    " - pyjet\n",
    "<br>\n",
    "\n",
    "### 2) Clustering\n",
    "Sometimes we have data with 4-momenta form, either (px,py,pz,e) or (pT,eta,phi,mass)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyjet import cluster\n",
    "\n",
    "def _load (filePath, nJets=200000, nConstituents=40):\n",
    "    '''\n",
    "    Returns:\n",
    "        momenta: (nJets, 4, nConstituents)\n",
    "    '''\n",
    "    cols = ['E_'+str(i) for i in range(nConstituents)]+ ['PX_'+str(i) for i in range(nConstituents)] + ['PX_'+str(i) for i in range(nConstituents)] + ['PY_'+str(i) for i in range(nConstituents)] + ['PZ_'+str(i) for i in range(nConstituents)] + ['is_signal_new']\n",
    "    df = pd.read_hdf(filePath,key='table',stop=nJets, columns = cols)\n",
    "    # Take all the 4 momentum from 200 particles in all jets and reshape them into one particle per row\n",
    "    momenta = df.iloc[:,:-1].to_numpy()\n",
    "    momenta = momenta.reshape(-1,nConstituents,4)\n",
    "    nJets = slice(nJets)\n",
    "    momenta = momenta[nJets, :nConstituents, :]\n",
    "    momenta = np.transpose(momenta, (0, 2, 1))\n",
    "    label = df['is_signal_new']\n",
    "    return momenta, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"data/4m_samples.h5\"\n",
    "nJets = 100\n",
    "nConstituents = 40\n",
    "data,labels = _load(filePath,nJets , nConstituents)\n",
    "\n",
    "data = np.core.records.fromarrays( [data[:,0],data[:,1],event[:,2],event[:,3]], names= 'E, PX, PY, PZ' , formats = 'f8, f8, f8,f8')\n",
    "'''\n",
    "R: Clustering radius for the main jets\n",
    "p = -1, 0, 1 => anti-kt, C/A, kt Algorithm\n",
    "ep = False, True => (px,py,pz,e) , (pT,eta,phi,mass)\n",
    "'''\n",
    "sequence = cluster(eventCopy, R=R0, p= p, ep=True)"
   ]
  },
  {
   "source": [
    "### 3) Rotating\n",
    "Rotation is performed to remove the stochastic nature of the decay angle relative to the η − φ coordinate system. For two-body decay processes (such as the hadronic decay of a W boson) the direction connecting the axes of the leading two subjets can be rotated until the leading subject is directly above the subleading subjet.\n",
    "<br><br>\n",
    "More information about Jet-Image: [Paper](https://arxiv.org/pdf/1407.5675.pdf)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rotate(event, R0 = 0.2,  p = 1):\n",
    "    '''\n",
    "    input:\n",
    "        event: (nConstituents,4)\n",
    "        R0 = Clustering radius for the main jets\n",
    "        p = -1, 0, 1 => anti-kt, C/A, kt Algorithm\n",
    "    '''\n",
    "    event = np.transpose(event,(1,0))\n",
    "    eventCopy = np.core.records.fromarrays( [event[:,0],event[:,1],event[:,2],event[:,3]], names= 'E, PX, PY, PZ' , formats = 'f8, f8, f8,f8')\n",
    "    sequence = cluster(eventCopy, R=R0, p= p, ep=True)\n",
    "    # List of jets\n",
    "    jets = sequence.inclusive_jets()\n",
    "    if len(jets)<2:\n",
    "        return []\n",
    "    else:\n",
    "        subjet_data = event\n",
    "        subjet_array = jets\n",
    "        \n",
    "        p = np.linalg.norm(event[:, 1:], axis=1)\n",
    "        eta = 0.5 * np.log((p + event[:, 3]) / (p - event[:, 3]))\n",
    "        phi = np.arctan2(event[:, 2], event[:, 1])\n",
    "                \n",
    "        # Shift all data such that the leading subjet\n",
    "        # jet new center is located at (eta,phi) = (0,0)\n",
    "        eta -= subjet_array[0].eta\n",
    "        phi = np.array( [_deltaPhi(i,subjet_array[0].phi) for i in phi])\n",
    "        \n",
    "        # Rotate the jet image such that the second leading\n",
    "        # jet is located at -pi/2\n",
    "        s1x, s1y = subjet_array[1].eta - subjet_array[0].eta, _deltaPhi(subjet_array[1].phi,subjet_array[0].phi)\n",
    "        \n",
    "        theta = np.arctan2(s1y, s1x)\n",
    "        if theta < 0.0:\n",
    "            theta += 2 * np.pi\n",
    "        etaRot, phiRot = _rotate2D(eta, phi, np.pi - theta)\n",
    "        \n",
    "        # Collect the trimmed subjet constituents\n",
    "        return etaRot, phiRot"
   ]
  },
  {
   "source": [
    "### 4) Excercise\n",
    "Try to generate jet image with 4-momenta data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}